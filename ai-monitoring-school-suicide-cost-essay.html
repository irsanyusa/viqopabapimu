<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=robots content="index,follow,noarchive"><title>AI Monitoring in Schools Can Come at a Great Cost - ZedJ</title><meta name=description content="Suicide is now the second leading cause of death among American youth between the ages of 10 and 14. The problem of youth suicide has only gotten worse lately, in part due to a nationwide shortage of mental health professionals, particularly in schools, where if available, an on-staff psychologist, counselor or social worker can help"><meta name=author content="Some Person"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"ZedJ","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"\/ai-monitoring-school-suicide-cost-essay.html","name":"Ai monitoring in schools can come at a great cost"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Reinaldo Massengill"},"headline":"AI Monitoring in Schools Can Come at a Great Cost","description":"Suicide is now the second leading cause of death among American youth between the ages of 10 and 14. The problem of youth suicide has only gotten worse lately, in part due to a nationwide shortage of mental health professionals, particularly in schools, where if available, an on-staff psychologist, counselor or social worker can help","inLanguage":"en","wordCount":1377,"datePublished":"2024-08-13T00:00:00","dateModified":"2024-08-13T00:00:00","image":"\/img\/avatar-icon.png","keywords":[""],"mainEntityOfPage":"\/ai-monitoring-school-suicide-cost-essay.html","publisher":{"@type":"Organization","name":"\/","logo":{"@type":"ImageObject","url":"\/img\/avatar-icon.png","height":60,"width":60}}}</script><meta property="og:title" content="AI Monitoring in Schools Can Come at a Great Cost"><meta property="og:description" content="Suicide is now the second leading cause of death among American youth between the ages of 10 and 14. The problem of youth suicide has only gotten worse lately, in part due to a nationwide shortage of mental health professionals, particularly in schools, where if available, an on-staff psychologist, counselor or social worker can help"><meta property="og:image" content="/img/avatar-icon.png"><meta property="og:url" content="/ai-monitoring-school-suicide-cost-essay.html"><meta property="og:type" content="website"><meta property="og:site_name" content="ZedJ"><meta name=twitter:title content="AI Monitoring in Schools Can Come at a Great Cost"><meta name=twitter:description content="Suicide is now the second leading cause of death among American youth between the ages of 10 and 14. The problem of youth suicide has only gotten worse lately, in part due to a nationwide shortage of …"><meta name=twitter:image content="/img/avatar-icon.png"><meta name=twitter:card content="summary"><meta name=twitter:site content="@username"><meta name=twitter:creator content="@username"><link href=./img/favicon.ico rel=icon type=image/x-icon><meta name=generator content="Hugo 0.98.0"><link rel=alternate href=./index.xml type=application/rss+xml title=ZedJ><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css integrity=sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.5.0/css/all.css integrity=sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/highlight.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous></head><body><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><h1>AI Monitoring in Schools Can Come at a Great Cost</h1><span class=post-meta><i class="fas fa-calendar"></i>&nbsp;Posted on August 13, 2024
&nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;7&nbsp;minutes
&nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;1377&nbsp;words
&nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Reinaldo Massengill</span></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><img src=https://cdn.statically.io/img/api.time.com/wp-content/uploads/2024/02/ai-trackingi-students.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px"><span class="leading-7 float-left border-t-2 border-l-2 border-solid border-time-red text-5xl py-2 pr-0.5 pl-[0.3125rem] my-0.5 mr-2.5 font-zilla-slab">S</span>uicide is now the <a href=#>second leading cause of death</a> among American youth between the ages of 10 and 14. The problem of youth suicide has only gotten worse lately, in part due to a <a href=#>nationwide shortage</a> of mental health professionals, particularly in <a href=#>schools</a>, where if available, an on-staff psychologist, counselor or social worker can help identify at-risk youth, and take steps toward an appropriate <a href=#>intervention</a>.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">As a remedy, school administrators, faced with daunting funding and staffing shortages, have increasingly looked to technology to help them manage the youth suicide crisis. Specifically, companies such as Bark, Gaggle, GoGuardian and Securly have developed technology in the form of <a href=#>AI-based student monitoring software</a> that tracks students’ computer use to identify students facing mental health challenges. It is <a href=#>generally designed</a> to operate in the background of students’ school issued computing devices and accounts, and flag activity that may indicate that they are at risk for self-harm.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">This tracking software is being used nationwide, on millions of students. But many parents and community members remain unaware of its existence. Students may have some sense that their school devices are being monitored, but likely have a limited understanding of how it is used. And even though identifying suicide risk might be a worthwhile objective, AI surveillance may feel like a significant breach of privacy, while also posing other unanticipated harms.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">As researchers whose work has focused on dimensions of inequality, mental health, and technology policy, we interviewed and talked to staff to better understand the benefits and risks of this software. One superintendent told us that this monitoring software can identify at-risk students who may not already be on the radar of school staff, providing them with an opportunity to intervene before the situation gets worse. &nbsp;</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">We are researchers, but we are all also parents, and this added layer of safety for suicide risk detection can feel, at first, like a no-brainer. The idea of losing a child is terrifying, and so it is completely understandable that schools would reach for a seemingly low-cost tool that can “catch” the private, sensitive, suicide-related thoughts that students might not disclose to anyone outside their Google search bar.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">But the problem is that, apart from anecdotes, there is little hard evidence supporting the accuracy of this software, and there are numerous examples throughout history where well-meaning <a href=#>approaches</a> to mental health intervention have caused <a href=#>unintended harms</a>. Similarly, it is increasingly clear that emerging technology also has a range of <a href=#>harmful collateral effects</a> on youth mental health.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px"><strong>Read More: </strong><a href=#>It Will Take More Than Robots to Manage the Robots</a></p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Through a careful review of the existing evidence, and through interviews with dozens of school staff, parents, and others, we found that AI based monitoring, far from being a solution to the persistent and growing problem of youth suicide, might well give rise to more problems than what it seeks to solve.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">First, the use of AI-based monitoring threatens student privacy. Because the software runs while students use their school-issued computing devices and accounts, it has the potential to collect large amounts of data about their lives. While some companies have taken <a href=#>voluntary pledges</a> to safeguard student data, there is no national regulation restricting much of the data that are collected, how they are stored, and whether they are shared.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Adding to this privacy risk, families may find it difficult to opt-out of using the software. We find that across many school districts, families are required to consent to AI-based monitoring as a condition of using school-issued computing devices to begin with. If families opt out of monitoring, they must provide their own computer for school use, which is not an affordable option for many families.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Second, our research shows that many parents and researchers have <a href=#>concerns</a> that using AI-based algorithms to identify at-risk students could exacerbate inequalities. For example, there have been <a href=#>reports</a> that internet searches of LGBTQ+ students have been flagged at disproportionate rates by AI software. Their activities may then be brought to the attention of school officials, involuntarily “outing” these students.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">The potential for suicide risk prediction algorithms to be biased against minoritized groups has been well documented through other <a href=#>studies</a>. And while many have claimed that these algorithms can be <a href=#>corrected for bias,</a> there is a lack of transparency about just how and when AI alerts get generated, which makes it difficult to audit the data in order to better understand if, indeed, it is biased. Another 2023 <a href=#>study</a> raised further concerns about the alerts generated by AI-based student monitoring software, documenting that the programs consistently flag content related to race, gender and sexual orientation. This includes searches related to topics such as Malcolm X and the Gay Men’s Chorus of Washington.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Lastly, while the AI software does the flagging of kids, it is then up to schools to decide how to respond to alerts they receive. Throughout our interviews, we heard stories of alerts generated by AI-based monitoring being used to discipline students. For example, we talked to a teacher who told us about a student experiencing a mental health challenge who was suspended from school, rather than meeting with a counselor or other mental health professionals.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Worse still, AI based monitoring might lead to increased encounters between students and law enforcement. For example, we found that, on weekends and school holidays, when they do not have staff on hand to review information, many schools automatically direct AI-generated suicide risk alerts to local law enforcement. From the school’s point of view, such a move is often the best way to ensure that a student experiencing a mental health crisis receives immediate help. But law enforcement might not be best positioned to help students in need of support, and might even <a href=#>exacerbate problems</a>. This is something we have already seen in other <a href=#>situations</a>, when police have been called in to assist with mental health crises; the risk of <a href=#>violent interactions</a> with law enforcement is real—especially for youth of color—and must be considered in weighing the pros and cons of using these tools.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Some people we interviewed also pointed out that this software has the potential to fuel existing inequalities regarding school discipline. For example, we know that students of color already face <a href=#>disproportionately high</a> school disciplinary actions, such as suspensions and expulsions, which is connected to the <a href=#>school-to-prison-pipeline</a>. Alerts created by AI software could fuel these disparities by increasing the likelihood of law enforcement contact.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px"><strong>Read More:</strong> <a href=#>How Racism Affects the Mental Health of Black Youth</a></p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Ultimately, it remains unclear whether tools can accurately detect suicide risk in students. So far no studies have followed up with the students these programs have flagged as “at risk” for suicide, to see if they actually were at risk (“true positives”) or not (“false positives”); nor have studies looked at the extent to which students at risk for suicide were not flagged by the programs (“false negatives”). School and law enforcement responses to these alerts, and ultimate student outcomes—whether a student receives medical attention or mental health care, or if a flagged student has a violent encounter with law enforcement—are also not documented. This lack of evidence means it is not clear that benefits of the software outweigh the risks we found in our research.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Parents, students, school staff, and health professionals must carefully weigh the potential benefits and challenges of AI-based monitoring. While it may serve as an important resource for schools amidst a growing youth mental health crisis, the actual, realized benefits and harms of this technology—including whether it can accurately detect suicide risk—are unknown.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">In the meantime, as school districts use their budgets to deploy AI based tools for suicide risk detection, it is important to recognize the known problems. The software raises important privacy concerns and has the possibility to perpetuate existing inequalities. As a result, AI companies and schools must ensure that families have comprehensive information about how the software is being used. Families should also be able to opt-out of monitoring without penalty. In addition, more regulation is needed on the federal, state, and local levels, to ensure safeguards are in place to protect students so that this software, which is after all designed to improve students’ mental health outcomes, does not end up doing more harm than good.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmismaKyb6%2FOpmZvbmlpgXOBjpqgZqWfo7a1u9GipaBlo5i1sLvLZqquoZOesaZ5wqiqrWWVqMCixY4%3D</p><hr><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><ul class=share><li><a href="//twitter.com/share?url=%2fai-monitoring-school-suicide-cost-essay.html&text=AI%20Monitoring%20in%20Schools%20Can%20Come%20at%20a%20Great%20Cost&via=username" target=_blank title="Share on Twitter"><i class="fab fa-twitter"></i></a></li><li><a href="//www.facebook.com/sharer/sharer.php?u=%2fai-monitoring-school-suicide-cost-essay.html" target=_blank title="Share on Facebook"><i class="fab fa-facebook"></i></a></li><li><a href="//reddit.com/submit?url=%2fai-monitoring-school-suicide-cost-essay.html&title=AI%20Monitoring%20in%20Schools%20Can%20Come%20at%20a%20Great%20Cost" target=_blank title="Share on Reddit"><i class="fab fa-reddit"></i></a></li><li><a href="//www.linkedin.com/shareArticle?url=%2fai-monitoring-school-suicide-cost-essay.html&title=AI%20Monitoring%20in%20Schools%20Can%20Come%20at%20a%20Great%20Cost" target=_blank title="Share on LinkedIn"><i class="fab fa-linkedin"></i></a></li><li><a href="//www.stumbleupon.com/submit?url=%2fai-monitoring-school-suicide-cost-essay.html&title=AI%20Monitoring%20in%20Schools%20Can%20Come%20at%20a%20Great%20Cost" target=_blank title="Share on StumbleUpon"><i class="fab fa-stumbleupon"></i></a></li><li><a href="//www.pinterest.com/pin/create/button/?url=%2fai-monitoring-school-suicide-cost-essay.html&description=AI%20Monitoring%20in%20Schools%20Can%20Come%20at%20a%20Great%20Cost" target=_blank title="Share on Pinterest"><i class="fab fa-pinterest"></i></a></li></ul></div></div></section></article><ul class="pager blog-pager"><li class=previous><a href=./doctor-who-indira-varma-duchess-game-of-thrones-1235624006.html data-toggle=tooltip data-placement=top title="Game of Thrones Actor Indira Varma Joins Doctor Who as The Duchess">&larr; Previous Post</a></li><li class=next><a href=./aehnlichkeiten-deutsch-englisch.html data-toggle=tooltip data-placement=top title="10 Grnde, warum sich Deutsch und Englisch hneln">Next Post &rarr;</a></li></ul></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href title=RSS><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="credits copyright text-muted">All rights reserved
&nbsp;&bull;&nbsp;&copy;
2024
&nbsp;&bull;&nbsp;
<a href=./>ZedJ</a></p><p class="credits theme-by text-muted"><a href=https://gohugo.io>Hugo v0.98.0</a> powered &nbsp;&bull;&nbsp; Theme <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> adapted from <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a></p></div></div></div></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js integrity=sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js integrity=sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe crossorigin=anonymous></script>
<script src=https://code.jquery.com/jquery-1.12.4.min.js integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin=anonymous></script>
<script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script src=https://assets.cdnweb.info/hugo/bh/js/main.js></script>
<script src=https://assets.cdnweb.info/hugo/bh/js/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0")})</script><script>renderMathInElement(document.body)</script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=https://assets.cdnweb.info/hugo/bh/js/load-photoswipe.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>